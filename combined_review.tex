\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{multirow}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Comprehensive Review of Deep Reinforcement Learning Strategies for UAV Navigation and Conflict Resolution: A 16-Study Analysis}

\author{\IEEEauthorblockN{Harshvardhan Pandey}
\IEEEauthorblockA{\textit{Dept. of Artificial Intelligence and Machine Learning} \\
\textit{Manipal University Jaipur}\\
Jaipur, India \\
harshpandey145@gmail.com}
\and
\IEEEauthorblockN{Adya Chauhan}
\IEEEauthorblockA{\textit{Dept. of Artificial Intelligence and Machine Learning} \\
\textit{Manipal University Jaipur}\\
Jaipur, India \\
adyachauhan.04@gmail.com}
\and
\IEEEauthorblockN{Yash Prasad}
\IEEEauthorblockA{\textit{Dept. of Artificial Intelligence and Machine Learning} \\
\textit{Manipal University Jaipur}\\
Jaipur, India \\
eyash.prasad24@gmail.com}
}

\maketitle

\begin{abstract}
The autonomous navigation of Unmanned Aerial Vehicles (UAVs) in complex, dynamic, and unknown environments remains a critical challenge, particularly in the absence of reliable communication or global positioning. Traditional path planning algorithms (e.g., A*, RRT) often struggle with real-time adaptability and computational efficiency in high-dimensional state spaces. Deep Reinforcement Learning (DRL) has emerged as a powerful paradigm to address these limitations by enabling end-to-end learning of control policies directly from sensor inputs. This paper presents an extensive, in-depth review of sixteen cutting-edge studies on DRL-based and hybrid UAV navigation systems. We dissect each approach based on network architecture, reward function design, training methodologies, and quantitative performance metrics. Furthermore, we provide a comprehensive comparative analysis using standardized metrics such as algorithm class, state-space dimensionality, and simulation environments. Our synthesis reveals a growing trend towards hybrid architectures combining DRL with classical planners, the use of attention mechanisms for better feature extraction, and the critical role of reward shaping in convergence. Finally, we identify key gaps in current research, particularly the scarcity of real-world validation and the need for more robust sim-to-real transfer protocols.
\end{abstract}

\begin{IEEEkeywords}
Unmanned Aerial Vehicles (UAV), Deep Reinforcement Learning (DRL), Path Planning, Obstacle Avoidance, Neural Networks, Autonomous Navigation
\end{IEEEkeywords}

\input{sections/01_introduction.tex}
\input{sections/02_preliminaries.tex}
\input{sections/03_value_based.tex}
\input{sections/04_policy_based.tex}
\input{sections/05_hybrid_non_drl.tex}
\input{sections/06_comparative_analysis.tex}
\input{sections/07_challenges_future.tex}

\begin{thebibliography}{00}
\bibitem{b1} Wang et al., "Deep-reinforcement-learning-based UAV autonomous navigation..."
\bibitem{b2} Fremond et al., "Adaptive Multi-Agent Reinforcement Learning..."
\bibitem{b3} Carvalho et al., "UAV Navigation in 3D Urban Environments..."
\bibitem{b4} Xue and Chen, "Combining Motion Planner and Deep Reinforcement Learning..."
\bibitem{b5} Yin et al., "Autonomous UAV Navigation with Adaptive Control..."
\bibitem{b6} Duan et al., "Multi-Level-Frontier Empowered Adaptive Path Planning..."
\bibitem{b7} J. Wang et al., "APPA-3D: an autonomous 3D path planning algorithm...", Nature Sci Rep, 2024.
\bibitem{b8} F. AlMahamid et al., "Agile DQN: adaptive deep recurrent attention...", Nature Sci Rep, 2024.
\bibitem{b9} H. Samma et al., "Autonomous UAV Visual Navigation Using an Improved DRL", IEEE Access, 2024.
\bibitem{b10} Y. Yan et al., "SIGN: Safety-Aware Image-Goal Navigation...", Arxiv, 2025.
\bibitem{b11} Z. Feiyu et al., "Autonomous localized path planning... based on TD3", Nature Sci Rep, 2024.
\bibitem{b12} J. Woo et al., "Deep reinforcement learning-based controller for path following of a USV", Ocean Eng, 2019.
\bibitem{b13} R. Wu et al., "A multi-critic deep deterministic policy gradient UAV path planning", IEEE CIS, 2020.
\bibitem{b14} R. Xie et al., "UAV Path Planning... in Large-Scale and Dynamic Environments", IEEE Access, 2021.
\bibitem{b15} X. Chen et al., "Collaborative Path Planning... to Avoid Sudden Threats", Shenyang Aerospace.
\bibitem{b16} H. Cheng et al., "Cooperative control of UAV swarm via information measures", IJIUS.
\end{thebibliography}

\end{document}
